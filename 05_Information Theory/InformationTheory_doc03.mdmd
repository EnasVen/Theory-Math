# Information 理解
Cross-Entropy 在機器學習/深度學習都是常用的metric。要理解就必須回到entropy最初的定義。

我們都知道資訊量可以透過log進行量化: 
<img src="https://latex.codecogs.com/gif.image?\dpi{110}I(x)&space;=&space;-log_2p(x)" title="https://latex.codecogs.com/gif.image?\dpi{110}I(x) = -log_2p(x)" />
