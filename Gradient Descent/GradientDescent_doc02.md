梯度下降的方法，常見的有6種，各自介紹如下:  

# Vanilla Gradient Descent
最基礎的Gradient Descent，形式如上一份markdown文件所述:  
<img src="https://latex.codecogs.com/png.image?\dpi{110}&space;w_{t&plus;1}&space;=&space;w_t&space;-&space;\eta_t&space;*&space;g_t&space;\;&space;,&space;\;&space;where&space;\;&space;g_t&space;=&space;\frac{\partial&space;L}{\partial&space;w}"/>

# Adaptive Gradient Descent

# Stochastic Gradient Descent

# RMA Prop

# Momentum
